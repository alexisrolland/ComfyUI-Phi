accelerate>=1.3.0
# flash_attn~=2.8  # If you want to use flash_attention_v2 see install process in https://github.com/Dao-AILab/flash-attention?tab=readme-ov-file#installation-and-features
backoff>=2.2.1
peft>=0.13.2